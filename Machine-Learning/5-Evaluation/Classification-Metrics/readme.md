In the lecture on Classification Metrics and Evaluation Techniques, you learned about the following key concepts:

Supervised Learning Evaluation: This process assesses how well a machine learning model predicts outcomes for unseen data, crucial for understanding model effectiveness.

Train-Test-Split Technique: The dataset is divided into a training set (70-80% of the data) for training the model and a test set for evaluating its performance on new data.

Common Metrics for Evaluation:
    Accuracy: The ratio of correctly predicted instances to the total instances.
    Confusion Matrix: A table that shows true positives, true negatives, false positives, and false negatives.
    Precision: The fraction of true positives among all predicted positives.
    Recall: The fraction of true positives among all actual positives.
    F1 Score: The harmonic mean of precision and recall, useful when both metrics are important.

========================================================================================================================================